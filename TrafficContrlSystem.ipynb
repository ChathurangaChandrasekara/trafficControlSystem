{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Object_Detection_Images.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChathurangaChandrasekara/trafficControlSystem/blob/main/TrafficContrlSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJQtOMvGSwJu",
        "outputId": "27bfbf17-0127-4221-c361-7c85bd8f5ae0"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "import cv2\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2301, done.\u001b[K\n",
            "remote: Counting objects: 100% (2301/2301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1999/1999), done.\u001b[K\n",
            "remote: Total 2301 (delta 560), reused 931 (delta 279), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2301/2301), 30.60 MiB | 10.53 MiB/s, done.\n",
            "Resolving deltas: 100% (560/560), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fVdV-y3fZFo",
        "outputId": "5be95fd9-155c-46d9-e9a9-b2a0c6247f04"
      },
      "source": [
        "path = os.getcwd()\n",
        "print(path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "q4FtYqVVSwJv",
        "outputId": "cb09f8e6-d43b-4e61-acc3-a81888eb1c32"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import pathlib\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-50e944b66391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvis_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/research/object_detection/utils/ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtf_slim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstandard_fields\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshape_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_slim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DJ3A1uXSwJv"
      },
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVRSDtjaSwJw"
      },
      "source": [
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name, \n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "  model = tf.compat.v2.saved_model.load(str(model_dir), None)\n",
        "  model = model.signatures['serving_default']\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdhphy81SwJw"
      },
      "source": [
        "path = os.getcwd()\n",
        "print(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGIoo1OYSwJz"
      },
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd_rhTmeSwJz"
      },
      "source": [
        "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "detection_model = load_model(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuBr4V-OSwJ0"
      },
      "source": [
        "print(detection_model.inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T16dac-SwJ1"
      },
      "source": [
        "detection_model.output_dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfClkWVASwJ2"
      },
      "source": [
        "detection_model.output_shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBhSmEhpSwJ3"
      },
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  output_dict = model(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPOq3ohQSwJ3"
      },
      "source": [
        "def show_inference(model, image_path):\n",
        "    \n",
        "#   image_np = np.array(Image.open(image_path))\n",
        "  image_np = image_path\n",
        "\n",
        "  image_np=cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=2,\n",
        "      skip_labels=True)\n",
        "\n",
        "#   image_np=cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)\n",
        "#   display(Image.fromarray(image_np))\n",
        "    \n",
        "  output_list = get_count(output_dict['detection_boxes'],output_dict['detection_scores'],output_dict['detection_classes'])\n",
        "  output_length = get_length(image_np,output_list[0],output_list[1],output_list[2])\n",
        "  print(\"Detected object count :\",output_list[3])\n",
        "  print(\"Pixel value of queue length :\",output_length[0])\n",
        "\n",
        "  display(Image.fromarray(image_np))\n",
        "    \n",
        "  return output_list[3],output_length[0],image_np\n",
        " \n",
        "#   return output_list[3],image_np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "w8Ig16UPSwJ3"
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('test-image/new-image')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*g\")))\n",
        "TEST_IMAGE_PATHS\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "lEkSo4wSSwJ4"
      },
      "source": [
        "import os\n",
        "d = \"test-image/new-image\"\n",
        "for path in os.listdir(d):\n",
        "    full_path = os.path.join(d, path)\n",
        "    if os.path.isfile(full_path):\n",
        "        img = cv2.imread(full_path)\n",
        "        img = show_inference(detection_model, img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "N2Hd8vsUSwJ9"
      },
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    print(image_path)\n",
        "    \n",
        "#     print(img)\n",
        "#     img = cv2.imread(image_path)\n",
        "#     img = show_inference(detection_model, img)\n",
        "#     print(img)\n",
        "#     if img!=None:\n",
        "#         window_name = 'image'\n",
        "#         cv2.imshow(window_name,img)\n",
        "#         cv2.waitKey(0)\n",
        "#         cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAaAet8hSwJ9"
      },
      "source": [
        "# def get_vehicle(classes,scores):\n",
        "#     vehicle_classes = [2,3,4,6,8]\n",
        "#     c = 0\n",
        "#     class_array = []\n",
        "#     score_array = []\n",
        "# #     print('classes = ',classes)\n",
        "# #     print('lenght = ', len(classes))\n",
        "# #     print('scores = ',scores)\n",
        "# #     print('lenght = ', len(scores))\n",
        "#     for i in classes:\n",
        "#         for x in vehicle_classes:\n",
        "#             if i==x:\n",
        "#                 class_array.append(i)\n",
        "#                 score_array.append(scores[c])\n",
        "#         c += 1\n",
        "    \n",
        "#     print('class_array = ',class_array)\n",
        "#     print('lenght = ', len(class_array))\n",
        "#     print('score_array = ',score_array)\n",
        "#     print('lenght = ', len(score_array))\n",
        "#     return class_array,score_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut10C8lQSwJ9"
      },
      "source": [
        "def get_count(boxes,scores,classes):  \n",
        "    count = 0\n",
        "    vehicle_classes = [2,3,4,6,8]\n",
        "    class_array = []\n",
        "    score_array = []\n",
        "    box_array = []\n",
        "#     category_index = { 2: {'id': 2, 'name': 'bicycle'}, 3: {'id': 3, 'name': 'car'}, 4: {'id': 4, 'name': 'motorcycle'}, 6: {'id': 6, 'name': 'bus'}, 8: {'id': 8, 'name': 'truck'}}\n",
        "    output = []\n",
        "    \n",
        "    for i in range(100):\n",
        "        if (scores[i] > 0.5):\n",
        "            for x in vehicle_classes:\n",
        "                if(classes[i] == x):\n",
        "                    class_array.append(x)\n",
        "                    score_array.append(scores[i])\n",
        "                    box_array.append(boxes[i])\n",
        "                    \n",
        "    x = len(class_array)\n",
        "    output.append(class_array)\n",
        "    output.append(score_array)\n",
        "    output.append(box_array)\n",
        "    output.append(x)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvY28tueSwJ-"
      },
      "source": [
        "def get_length(image,classes,score,boxes):\n",
        " MinY,MaxY,X,Length = 2,0,0.1,0\n",
        " c = 0\n",
        " for i in classes:\n",
        "        h,w=image.shape[0:2]\n",
        "    #   image.shape=[height,width,3]\n",
        "        ymin,xmin,ymax,xmax=boxes[c]\n",
        "        c += 1\n",
        "        if MaxY<ymax:\n",
        "            MaxY = ymax\n",
        "#             X = xmax\n",
        "        if MinY>ymin:\n",
        "            MinY = ymin\n",
        "\n",
        "            \n",
        " start_point = (int(round(X*w)),int(round(MinY*h))) \n",
        " end_point = (int(round(X*w)), int(round(MaxY*h)) )\n",
        " color = (255,0,0) \n",
        " thickness = 3\n",
        " Length = MaxY-MinY\n",
        "    # Using cv2.line() method \n",
        "    # Draw a diagonal green line with thickness of 5 px \n",
        " Image = cv2.line(image,start_point,end_point,color,thickness) \n",
        " return Length,Image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouL5n15eSwJ-"
      },
      "source": [
        "# PATH_TO_TEST_IMAGES_DIR = pathlib.Path('test-image')\n",
        "# TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*g\")))\n",
        "# TEST_IMAGE_PATHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-qn_PAKSwJ-"
      },
      "source": [
        "# for image_path in TEST_IMAGE_PATHS:\n",
        "#     show_inference(detection_model, image_path)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JwdqmnIVSwKB"
      },
      "source": [
        "# import cv2\n",
        "\n",
        "# img = cv2.imread('test-image\\A4.jpg')\n",
        "# # print(img)\n",
        "# img=show_inference(detection_model,img)\n",
        "# cv2.imshow('IMG',img)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b97w67fXSwKB"
      },
      "source": [
        "# import glob \n",
        "# img_dir = r\"test-image\"\n",
        "# data_path = os.path.join(img_dir,'*g')\n",
        "# files = glob.glob(data_path) \n",
        "\n",
        "# for file in files:\n",
        "#     img=show_inference(detection_model,file)\n",
        "#     cv2.imshow('IMG',file)\n",
        "#     cv2.waitKey(0)\n",
        "#     cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czZCORaGSwKB"
      },
      "source": [
        "# print(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQBKbDMfSwKC"
      },
      "source": [
        "import time\n",
        "Time = 0\n",
        "t = time.localtime()\n",
        "current_time = time.strftime(\"%H:%M\", t)\n",
        "# current_time = \"6:45\"\n",
        "t1 = \"6:30\"\n",
        "t2 = \"8:30\"\n",
        "t3 = \"12:30\"\n",
        "t4 = \"14:30\"\n",
        "t5 = \"17:00\"\n",
        "t6 = \"19:00\"\n",
        "\n",
        "print(current_time)\n",
        "\n",
        "if(t1<current_time<t2):\n",
        "    Time = 1\n",
        "    \n",
        "elif(t3<current_time<t4):\n",
        "    Time = 3\n",
        "    \n",
        "elif(t5<current_time<t6):\n",
        "    Time = 4\n",
        "else:\n",
        "    Time = 2\n",
        "    \n",
        "    \n",
        "print(Time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAMskB80SwKC"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "def detect_image():\n",
        "    c = 1\n",
        "    length = []\n",
        "    outputs = []\n",
        "    outputs.append(Time)\n",
        "    d = \"test-image\"\n",
        "    for path in os.listdir(d):\n",
        "        full_path = os.path.join(d, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            img = cv2.imread(full_path)\n",
        "            img = show_inference(detection_model, img)\n",
        "#             print('count A',c,' = ' ,img[0])\n",
        "#             print('pixel length A',c,' = ',img[1],'\\n')\n",
        "            L = round(img[1]*40)\n",
        "            outputs.append(img[0])\n",
        "            length.append(L)\n",
        "            c += 1\n",
        "    for i in length:\n",
        "        outputs.append(i)\n",
        "        \n",
        "    return outputs\n",
        "#         cv2.imshow('IMG',img[2])\n",
        "#         cv2.waitKey(0)\n",
        "#         cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzmFBOulSwKC"
      },
      "source": [
        "# def crop_objects(image, image_np, output_dict, i):\n",
        "#     global ymin, ymax, xmin, xmax\n",
        "#     width, height = image.size\n",
        "\n",
        "#     #Coordinates of detected objects\n",
        "#     ymin = int(output_dict['detection_boxes'][0][0]*height)\n",
        "#     xmin = int(output_dict['detection_boxes'][0][1]*width)\n",
        "#     ymax = int(output_dict['detection_boxes'][0][2]*height)\n",
        "#     xmax = int(output_dict['detection_boxes'][0][3]*width)\n",
        "#     crop_img = image_np[ymin:ymax, xmin:xmax]\n",
        "\n",
        "#     # 1. Only crop objects that are detected with an accuracy above 50%, \n",
        "#     # images \n",
        "#     # with objects below 50% will be filled with zeros (black image)\n",
        "#     # This is something I need in my program\n",
        "#     # 2. Only crop the object with the highest score (Object Zero)\n",
        "#     if output_dict['detection_scores'][0] < 0.5:\n",
        "#         crop_img.fill(0)\n",
        "\n",
        "#     #Save cropped object into image\n",
        "#     cv2.imwrite('Images/Step_2/' + str(i) + '.png', crop_img)\n",
        "#     return ymin, ymax, xmin, xmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e348YdRVSwKD"
      },
      "source": [
        "# import cv2\n",
        "\n",
        "# video = cv2.VideoCapture(r'D:/Tensorflow/sherbrooke_video.avi')\n",
        "\n",
        "# while(True):\n",
        "    \n",
        "#     ret,img=video.read()\n",
        "#     img=show_inference(detection_model,img)\n",
        "#     k=cv2.waitKey(1)\n",
        "#     cv2.imshow('LIVE',img)\n",
        "#     if(k==27):\n",
        "#         break\n",
        "# cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoZ1jlwwSwKD"
      },
      "source": [
        "# from datetime import datetime\n",
        "\n",
        "# def bicycle_detect(image,classes,score,boxes):\n",
        "    \n",
        "#     for i in range(100):\n",
        "#         if(classes[i]==4 and score[i]>0.8):\n",
        "            \n",
        "#             h,w=image.shape[0:2]\n",
        "# #             image.shape=[height,width,3]\n",
        "            \n",
        "#             ymin,xmin,ymax,xmax=boxes[i]\n",
        "\n",
        "# #             now = datetime.now()\n",
        "# #             dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
        "            \n",
        "#             center=(int(((xmin+xmax)/2)*w),int(((ymin+ymax)/2)*h))\n",
        "#             cv2.circle(image,center,10,(0,0,255),-1)\n",
        "            \n",
        "#             file_name=os.path.join('E:/TEST/',dt_string+'.jpg')\n",
        "#             cv2.imwrite(file_name,image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "z6nbvcZoSwKD"
      },
      "source": [
        "from tensorflow import keras\n",
        "inputs = detect_image()\n",
        "# print(image_detection)\n",
        "#Set Headship lane respectivly A1,A2,A3,A4\n",
        "headship = [1,1,0,0] \n",
        "for i in headship:\n",
        "    inputs.append(i)\n",
        "#Set Institutions respectivly A1,A2,A3,A4\n",
        "institutions = [1,0,1,0]\n",
        "for i in institutions:\n",
        "    inputs.append(i)\n",
        "    \n",
        "# print(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrhMcmG7SwKD"
      },
      "source": [
        "detection_model = keras.models.load_model(r'model_trained\\40-64model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1MhZrRxSwKD"
      },
      "source": [
        "detection_model.inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsz_WjXmSwKE"
      },
      "source": [
        "detection_model.outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "687tZx41SwKE"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = np.array([inputs])\n",
        "print(dataset.shape)\n",
        "print(dataset[0].shape)\n",
        "print(dataset[0:1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5h76U5eSwKF"
      },
      "source": [
        "prediction = detection_model.predict(dataset[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIyPfY2pSwKF"
      },
      "source": [
        "# print(prediction)\n",
        "result = np.argmax(prediction, axis=1)\n",
        "array_num = 0\n",
        "if(result==0):\n",
        "    print('Lane A1')\n",
        "    array_num = 1\n",
        "    \n",
        "elif(result==1):\n",
        "    print('Lane A2')\n",
        "    array_num = 2\n",
        "    \n",
        "elif(result==2):\n",
        "    print('Lane A3')\n",
        "    array_num = 3\n",
        "    \n",
        "elif(result==3):\n",
        "    print('Lane A4')\n",
        "    array_num = 4\n",
        "\n",
        "print('Time limit for green signal :',inputs[array_num]*7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t-pGFX9SwKF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp1DSA_6SwKF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}